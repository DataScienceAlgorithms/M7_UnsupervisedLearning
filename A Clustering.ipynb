{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CPSC 322]() Data Science Algorithms\n",
    "[Gonzaga University](https://www.gonzaga.edu/) |\n",
    "[Sophina Luitel](https://www.gonzaga.edu/school-of-engineering-applied-science/faculty/detail/sophina-luitel-phd-0dba6a9d)\n",
    "\n",
    "---\n",
    "\n",
    "# Clustering\n",
    "What are our learning objectives for this lesson?\n",
    "* Introduce k-means clustering\n",
    "* Evaluate the quality of a cluster using an objective function\n",
    "\n",
    "Content used in this lesson is based upon information in the following sources:\n",
    "* Dr. Gina Sprint's Data Science Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm-up Task(s)\n",
    "1. Create a new folder called ClusteringFun. In ClusteringFun, create a main.py and paste the following T-shirt sizes data:\n",
    "```python\n",
    "header = [\"height(cm)\", \"weight(kg)\"] #, \"size(t-shirt)\"]\n",
    "X_train = [\n",
    "    [158, 58], # \"M\"\n",
    "    [158, 59], # \"M\"\n",
    "    [158, 63], # \"M\"\n",
    "    [160, 59], # \"M\"\n",
    "    [160, 60], # \"M\"\n",
    "    [163, 60], # \"M\"\n",
    "    [163, 61], # \"M\"\n",
    "    [160, 64], # \"L\"\n",
    "    [163, 64], # \"L\"\n",
    "    [165, 61], # \"L\"\n",
    "    [165, 62], # \"L\"\n",
    "    [165, 65], # \"L\"\n",
    "    [168, 62], # \"L\"\n",
    "    [168, 63], # \"L\"\n",
    "    [168, 66], # \"L\"\n",
    "    [170, 63], # \"L\"\n",
    "    [170, 64], # \"L\"\n",
    "    [170, 68] # \"L\"\n",
    "]\n",
    "# TODO: normalize data before calculating distances\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today 11/19\n",
    "* Announcements\n",
    "    * Work on your project daily, make updates, and stay in touch with your partner.\n",
    "    * Take this opportunity to build your teamwork skills.\n",
    "    * IQ6 will be on Friday (next class) and topics to prepare:  [Ensemble Learning](https://github.com/DataScienceAlgorithms/M6_EnsembleLearning/blob/main/A%20Ensemble%20Learning.ipynb) and [Weighted Majority](https://github.com/DataScienceAlgorithms/M6_EnsembleLearning/blob/main/B%20Weighted%20Majority%20Voting.ipynb) Voting\n",
    "\n",
    "* Today \n",
    "    * LA12 starting 10 mins of class\n",
    "    * Review Unsupervised learning\n",
    "    * Clustering Lab\n",
    "    * Introduce k-means clustering\n",
    "    * Evaluate the quality of a cluster using an objective function\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### (Review) Unsupervised learning\n",
    "* Type of machine learning that analyzes and models data without label or predefined categories.\n",
    "* Works only with input data.\n",
    "* Used to discover hidden patterns, structures, or relationships within the dataset.\n",
    "#### Types of Unsupervised learning \n",
    "* Clustering \n",
    "    * Groups similar objects (instances) together (e.g., K-Means).\n",
    "* Association Rule Learning \n",
    "    * Finds patterns or relationships between items in a dataset, showing how the presence of some items is associated with others (e.g., Apriori).\n",
    "* Dimensionality Reduction\n",
    "    * Reduces feature while keeping important info (e.g., PCA).\n",
    "\n",
    "## Clustering\n",
    "Given a collection of \"objects\" (i.e., instances with attributes), determine similar groups of objects (\"clusters\").\n",
    "Assign objects to clusters using similarity or distance measures (e.g., Euclidean, cosine). **K-means** is one of the popular clustering algorithm.\n",
    "\n",
    "\n",
    "### Lab Task 1\n",
    "What are possible clusters for the following objects with two attributes?\n",
    "* When k = 4 clusters?\n",
    "* When k = 5 clusters?\n",
    "\n",
    "<img src=\"figures/cluster_example1.png\" width=\"450\"/>\n",
    "\n",
    "One possible set of solutions:\n",
    "\n",
    "<img src=\"figures/cluster_example2.png\" width=\"450\"/>\n",
    "\n",
    "Like with $k$-nn, need a distance metric\n",
    "* To determine how close instances so we can form clusters\n",
    "* We'll use Euclidean distance\n",
    "\n",
    "## Centroids\n",
    "A centroid is the point in the center of a cluster. Using Euclidean distances, a cluster's centroid is its \"average point\" ...\n",
    "* Specifically: each attribute value of the centroid is the average of the corresponding attribute value of the points in the cluster\n",
    "\n",
    "### Lab Task 2\n",
    "On paper, plot the following points of a cluster and plot its centroid (center point AKA average point of a cluster).\n",
    "\n",
    "|att1 |att2|\n",
    "|-|-|\n",
    "|3 |4|\n",
    "|6 |2|\n",
    "|2 |1|\n",
    "|5 |5|\n",
    "\n",
    "\n",
    "## $k$-Means clustering algorithm\n",
    "1. Pick a value of $k$\n",
    "1. Select $k$ objects (arbitrarily) to use as initial centroids\n",
    "1. Assign each instance to the cluster of its nearest centroid\n",
    "1. Recalculate the centroids for the $k$ clusters\n",
    "1. Repeat Steps 3-4 until the centroids no longer move (change)\n",
    "\n",
    "Note that the resulting clusters depend on initial instances used as centroids\n",
    "* e.g., starting with different instances can change the outcome\n",
    "* One approach is to randomly pick $k$ instances as centroids\n",
    "\n",
    "Q: What happens when $k$ = 1?\n",
    "* We end up with only one cluster!\n",
    "\n",
    "Q: What happens when $k = n$ for $n$ the number of instances?\n",
    "* We end up with 1 cluster per instance (so, the original dataset)!\n",
    "\n",
    "\n",
    "  \n",
    "Why clustering?\n",
    "* For prediction (e.g., determine instance's cluster, using voting)\n",
    "* For data reduction (reduce dataset to one instance per cluster)\n",
    "* For basic similarity search (e.g., find similar movies)\n",
    "* For data exploration\n",
    "\n",
    "## Lab Task 3\n",
    "Consider the following dataset consisting of nine two-dimensional data points. A (5,8), B (8,4), C (6,3), D (1,9), E (9,7), F (4,10), G (3,5), H (2,4), I (8,2). Use the k-means clustering algorithm to group these data points into clusters.\n",
    "\n",
    "\n",
    "## Cluster Quality\n",
    "The quality of the cluster is given by an \"objective function\"\n",
    "* i.e., a function we want to minimize (in this case)\n",
    "\n",
    "We'll use the \"Total Sum of Squares\" (TSS)\n",
    "* The sum of squared distances to the centroid from cluster instances\n",
    "$$TSS = \\sum_{i=1}^{n}((x_i - \\overline{x})^{2} + (y_i - \\overline{y})^{2})$$\n",
    "\n",
    "Can find good values for k experimentally- Elbow Method\n",
    "* In general, we want small values for $k$ (i.e., fewer clusters)\n",
    "* Start with $k$ = 2, then use TSS(total squared distance within clusters) to measure quality\n",
    "* Move to $k$ = 3, $k$ = 4, and so on, until TSS begins to converge\n",
    "* Select k at the first elbow point, where adding more clusters produces diminishing returns in TSS reduction.\n",
    "\n",
    "### Lab Task 4\n",
    "Calculate the TSS for the previous example.\n",
    "\n",
    "<!-- $$TSS = ((3 - 4)^2 + (4 - 3)^2) + ((6 - 4)^2 + (2 - 3)^2) +((2 - 4)^2 + (1 - 3)^2) + ((5 - 4)^2 + (5 - 3)^2) = 20$$\n",
    " -->\n",
    "\n",
    "Notes on the TSS:\n",
    "* Can work well here since we use Euclidean distance\n",
    "* Especially if we don't apply the square root function when calculating distances (can just add up the distances used)\n",
    "* TSS also penalizes bigger distances more\n",
    "\n",
    "### Lab Task 5\n",
    "Let's implement k-means clustering with k = 2 using height and weight data from [this site](https://www.listendata.com/2017/12/k-nearest-neighbor-step-by-step-tutorial.html)\n",
    "1. Starter code functions:\n",
    "    * `perform_k_means_clustering(table, k)`\n",
    "    * `compute_cluster_centroids(table, k)`\n",
    "    * `find_nearest_cluster(instance, centroids)`\n",
    "    * `check_clusters_moved(old_centroids, new_centroids)`\n",
    "1. (when your k-means algorithm is implemented) Is there a relationship between the clusters formed and T-shirt size?\n",
    "1. (when your k-means algorithm is implemented) Let's say there is a new customer named 'Monica' has height 161cm and weight 61kg. What cluster does Monica belong to? Can we conclude anything about her T shirt size?\n",
    "\n",
    "Note: because we use the Euclidean distance function, we don't want to forget to normalize the dataset before applying k-means clustering!!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
